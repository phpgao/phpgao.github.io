<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>crontab on 老高的技术博客</title>
    <link>https://phpgao.github.io/tags/crontab/</link>
    <description>Recent content in crontab on 老高的技术博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 17 Mar 2017 08:25:00 +0000</lastBuildDate><atom:link href="https://phpgao.github.io/tags/crontab/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cron在Centos上的安装方法</title>
      <link>https://phpgao.github.io/cron_on_centos.html</link>
      <pubDate>Fri, 17 Mar 2017 08:25:00 +0000</pubDate>
      
      <guid>https://phpgao.github.io/cron_on_centos.html</guid>
      <description>&lt;p&gt;Centos最小化安装时候貌似crond是不带的，需要自己手动安装。但是Centos不同的版本安装命令不一样，在此记录一下！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>获取所有用户的计划任务</title>
      <link>https://phpgao.github.io/crontab_for_everyone.html</link>
      <pubDate>Fri, 18 Mar 2016 10:44:00 +0000</pubDate>
      
      <guid>https://phpgao.github.io/crontab_for_everyone.html</guid>
      <description>一句话代码
cut -d: -f1 /etc/passwd|xargs -i sudo crontab -u {} -l </description>
    </item>
    
    <item>
      <title>模拟登录联通10010.com查询宽带余额</title>
      <link>https://phpgao.github.io/china_unicom_broadband_balance.html</link>
      <pubDate>Tue, 06 Jan 2015 06:46:00 +0000</pubDate>
      
      <guid>https://phpgao.github.io/china_unicom_broadband_balance.html</guid>
      <description>家里的宽带是包年按天扣费，时间长了就忘了改什么时候续费了。
抽时间写了个模拟登录10010.com的脚本，自动查询余额。
每天中午12点查一次，省得下次又欠费了。
模拟登录的过程很简单，获取查询的cookie需要两步请求，拿到cookie后可以随意查询。
有TX想看源码么？
已贴源码
#!/usr/bin/env python # encoding: utf-8 &amp;#34;&amp;#34;&amp;#34; @version: 0.2 @author: phpergao @license: Apache Licence @contact: endoffight@gmail.com @site: http://www.phpgao.com @software: PyCharm @file: 10010.py @time: 15-1-3 下午6:06 一键查询联通宽带余额 &amp;#34;&amp;#34;&amp;#34; import urllib2 import cookielib import json class Crawl(): def __init__(self, username, passwd, debug=False): (self.username, self.passwd) = (username, passwd) self.cookie = cookielib.CookieJar() cookieHandler = urllib2.HTTPCookieProcessor(self.cookie) self.is_debug = debug if self.is_debug: httpHandler = urllib2.HTTPHandler(debuglevel=1) httpsHandler = urllib2.HTTPSHandler(debuglevel=1) opener = urllib2.build_opener(cookieHandler, httpHandler, httpsHandler) else: opener = urllib2.</description>
    </item>
    
  </channel>
</rss>
